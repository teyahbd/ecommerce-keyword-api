{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step One: Cleaning the Dataset\n",
    "\n",
    "It is necessary to preprocess our data to get it into an appropriate and useful format for training our word vectors. To create custom trained word vectors, we need a corpus - a collection of sentences (or product descriptions in our case). Using these sentences, our training will create relationships between each of the words and quantify these as word vectors (or word embeddings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements\n",
    "\n",
    "- We are using an online retail dataset from the [UCI machine learning repository](https://archive.ics.uci.edu/ml/index.php) which can be downloaded [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/). \n",
    "\n",
    "- We will clean and train our data in Python - the programming language of choice for many machine learning and data science projects. We will make use of the popular ```pandas``` library to manipulate our dataset.\n",
    "\n",
    "Note: The training files are stored in this repo for convenience however, it would be most appropriate to create a new directory and virtual environment to the API directory and follow these steps there.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Data\n",
    "\n",
    "Our data is formatted as an Excel file, so we can read it into a ```pandas DataFrame```. As mentioned, we only need the \"Description\" column for our use so will only import this column.\n",
    "\n",
    "As our dataset is large, this may take a few minutes. Once this is completed, we should see the first few rows of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Description\n",
       "0   WHITE HANGING HEART T-LIGHT HOLDER\n",
       "1                  WHITE METAL LANTERN\n",
       "2       CREAM CUPID HEARTS COAT HANGER\n",
       "3  KNITTED UNION FLAG HOT WATER BOTTLE\n",
       "4       RED WOOLLY HOTTIE WHITE HEART."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Online_Retail.xlsx', usecols=\"C\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Data\n",
    "\n",
    "As our dataset has over half a million lines, it would not be practical to manually check for missing or nonsensical entries. Therefore, we must find ways to manipulate and clean the dataset as a whole so our model will be as useful as possible. This was a trial and error process specific to this dataset and there are likely further steps that could be added. \n",
    "\n",
    "1. Remove any empty rows\n",
    "\n",
    "There are some empty rows in our dataset, which we can check for. Make sure you run this block *before* removing the empty rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty rows before cleaning: Description    1454\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Empty rows before cleaning:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can remove these empty rows and check there are no null valued rows remaining. Make sure to modify the DataFrame in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty rows after cleaning: Description    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "\n",
    "print(\"Empty rows after cleaning:\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Remove non-product descriptions\n",
    "\n",
    "The next step in cleaning our data involves checking the contents of the sentences. In order to analyse our data line by line, we will convert our DataFram to a text file. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
